{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comment to get non-deterministic results\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This class implementation is inspired from the NN implemented in cours IFT6093\n",
    "class NN(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2, initialization='zeros', mode=',train',\n",
    "                 datapath=None,model_path=None):\n",
    "        \n",
    "        self.indim = input_dim\n",
    "        self.hd1 = hidden_dims[0] \n",
    "        self.hd2 = hidden_dims[1]\n",
    "        self.n_hidden = n_hidden\n",
    "        self.outd = output_dim\n",
    "        self.W1 = np.zeros(shape=(hidden_dims[0], input_dim))\n",
    "        #print('W1.shape =', self.W1.shape)\n",
    "        #print('W1 = ', self.W1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        self.b1 = np.zeros(hidden_dims[0])\n",
    "        #print('b1.shape =', self.b1.shape)\n",
    "        #print('b1 = ', self.b1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        self.W2 = np.zeros(shape=(hidden_dims[1], hidden_dims[0]))\n",
    "        #print('W2.shape =', self.W2.shape)\n",
    "        #print('W2 = ', self.W2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        self.b2 = np.zeros(hidden_dims[1])\n",
    "        #print('b2.shape =', self.b2.shape)\n",
    "        #print('b2 = ', self.b2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        self.W3 = np.zeros(shape=(output_dim, hidden_dims[1]))\n",
    "        #print('W3.shape =', self.W3.shape)\n",
    "        #print('W3 = ', self.W3)\n",
    "        #print('\\n')\n",
    "        \n",
    "        self.b3 = np.zeros(output_dim)\n",
    "        #print('b3.shape =', self.b3.shape)\n",
    "        #print('b3 = ', self.b3)\n",
    "        #print('\\n')\n",
    "        \n",
    "        if initialization=='normal':\n",
    "            self.initialize_weights_normal()\n",
    "            #print('W1 = ', self.W1)\n",
    "            #print('W2 = ', self.W2)\n",
    "            #print('W3 = ', self.W3)\n",
    "            \n",
    "            \n",
    "        if initialization=='glorot':\n",
    "            self.initialize_weights_glorot()\n",
    "            #print('W1 = ', self.W1)\n",
    "            #print('W2 = ', self.W2)\n",
    "            #print('W3 = ', self.W3)\n",
    "            \n",
    "        \n",
    "        self.parameters = [self.W3, self.b3, self.W2, self.b2, self.W1, self.b1]\n",
    "        \n",
    "        \n",
    "    def initialize_weights_normal(self):\n",
    "        \n",
    "        self.W1 = np.random.standard_normal(size=(self.hd1, self.indim))\n",
    "        self.W2 = np.random.standard_normal(size=(self.hd2, self.hd1))\n",
    "        self.W3 = np.random.standard_normal(size=(self.outd, self.hd2))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def initialize_weights_glorot(self):\n",
    "        \n",
    "        dl1 = np.sqrt(6/(self.indim + self.hd1))\n",
    "        dl2 = np.sqrt(6/(self.hd1 + self.hd2))\n",
    "        dl3 = np.sqrt(6/(self.hd2 + self.outd))\n",
    "        self.W1 = np.random.uniform(low=(-dl1), high=dl1, size=(self.hd1, self.indim))\n",
    "        self.W2 = np.random.uniform(low=(-dl2), high=dl2, size=(self.hd2, self.hd1))\n",
    "        self.W3 = np.random.uniform(low=(-dl3), high=dl3, size=(self.outd, self.hd2))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Method inspired from NN implemented in cours IFT6093\n",
    "    def activation (self,input):\n",
    "        return (input > 0) * input  \n",
    "    \n",
    "    #line 85\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print('forward')\n",
    "        \n",
    "        a1 = np.dot (self.W1, x) + self.b1 \n",
    "        #print('a1 = np.dot (self.W1, x) + self.b1')\n",
    "        #print('a1.shape =', a1.shape)\n",
    "        #print('a1 = ', a1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h1 = self.activation (a1)\n",
    "        #print('h1 = self.activation (a1)')\n",
    "        #print('h1.shape =', h1.shape)\n",
    "        #print('h1 = ', h1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        a2 = np.dot (self.W2, h1) + self.b2\n",
    "        #print('a2 = np.dot (self.W2, h1) + self.b2')\n",
    "        #print('a2.shape =', a2.shape)\n",
    "        #print('a2 = ', a2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h2 = self.activation (a2)\n",
    "        #print('h2 = self.activation (a2)')\n",
    "        #print('h2.shape =', h2.shape)\n",
    "        #print('h2 = ', h2)\n",
    "        #print('\\n')\n",
    "        \n",
    "    \n",
    "        oa = np.dot (self.W3, h2) + self.b3\n",
    "        #print('oa = np.dot (self.W3, h2) + self.b3')\n",
    "        #print('oa.shape =', oa.shape)\n",
    "        #print('oa = ', oa)\n",
    "        #print('\\n')\n",
    "        \n",
    "        os = self.softmax (oa, axis=0)\n",
    "        #print('os = softmax (oa)')\n",
    "        #print('os.shape =', os.shape)\n",
    "        #print('os = ', os)\n",
    "        #print('\\n')\n",
    "               \n",
    "        return a1, h1, a2, h2, oa, os\n",
    "    \n",
    "    \n",
    "\n",
    "    #Methods inspired from NN implemented in cours IFT6093\n",
    "    def loss (self, y, os):\n",
    "        return (y * (-np.log(os))).sum()\n",
    "    \n",
    "\n",
    "    def softmax (self,x,axis=1):\n",
    "        shiftx = x - np.max (x, axis=axis, keepdims=True)\n",
    "        exps = np.exp (shiftx)\n",
    "        y = exps / exps.sum (axis=axis, keepdims=True)\n",
    "        return y\n",
    "\n",
    "\n",
    "    def backward(self, x, y, a1, h1, a2, h2, oa, os, weight_decay=0, cache=None):\n",
    "        #print ('backward')\n",
    "        #print('x.shape = ', x.shape)\n",
    "        #print('y.shape = ', y.shape)\n",
    "        #print('os.shape = ', os.shape)\n",
    "        grad_oa = os - y\n",
    "        #print('grad_oa.shape =', grad_oa.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_W3 = np.outer (grad_oa, h2) + weight_decay * self.W3\n",
    "        #print('grad_W3.shape =', grad_W3.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_b3 = grad_oa\n",
    "        #print('grad_b3.shape =', grad_b3.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_h2 = np.dot (self.W3.T, grad_oa)\n",
    "        #print(' grad_h2.shape =', grad_h2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_a2 = (a2 > 0) * grad_h2\n",
    "        #print('grad_a2.shape =', grad_a2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_W2 = np.outer (grad_a2, h1) + weight_decay * self.W2\n",
    "        #print('grad_W2.shape =', grad_W2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_b2 = grad_a2 \n",
    "        #print('grad_b2.shape =', grad_b2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_h1 = np.dot (self.W2.T, grad_a2)\n",
    "        #print('grad_h1.shape =', grad_h1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_a1 = (a1 > 0) * grad_h1\n",
    "        #print('grad_a1.shape =', grad_a1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_W1 = np.outer (grad_a1, x) + weight_decay * self.W1\n",
    "        #print('grad_W1.shape =', grad_W1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grad_b1 = grad_a1\n",
    "        #print('grad_b1.shape =', grad_b1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        grads=[grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1]\n",
    "   \n",
    "        return grads\n",
    "\n",
    "\n",
    "\n",
    "    def update(self, grads, learning_rate):\n",
    "        for p, grad in zip(self.parameters, grads):\n",
    "            p -= learning_rate * grad\n",
    "        \n",
    "    #line 201   \n",
    "\n",
    "    def train_SGD(self, x, y_onehot, n, learning_rate=1e-1, weight_decay=0):\n",
    "        y= y_onehot\n",
    "        #print('x.shape = ', x.shape)\n",
    "        #print('y.shape = ', y.shape)\n",
    "        losses = 0\n",
    "        if (n==1):\n",
    "            a1, h1, a2, h2, oa, os = self.forward(x)\n",
    "            grads = self.backward(x, y, a1, h1, a2, h2, oa, os)\n",
    "            self.update(grads, learning_rate)\n",
    "            loss = self.loss(y, os)\n",
    "            losses += loss  \n",
    "            average_loss = losses / n\n",
    "        else:    \n",
    "            for j in range(x.shape[0]):\n",
    "                a1, h1, a2, h2, oa, os = self.forward(x[j])\n",
    "                grads = self.backward(x[j], y[j], a1, h1, a2, h2, oa, os)\n",
    "                self.update(grads, learning_rate)\n",
    "                loss = self.loss(y[j], os)\n",
    "                losses += loss \n",
    "                \n",
    "            average_loss = losses / n\n",
    "            #print (average_loss)\n",
    "\n",
    "        #print (average_loss)   \n",
    "        return average_loss\n",
    "    \n",
    "    \n",
    "    def prediction_SGD (self, x):\n",
    "        predictions = np.zeros(x.shape[0])\n",
    "        for i in range(x.shape[0]):\n",
    "            _, _, _, _, _, os = self.forward(x[i])\n",
    "            predictions[i] = os.argmax()\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def accuracy_SGD (self, prediction, y):\n",
    "        accuracies=0\n",
    "        for i in range (y.shape[0]):\n",
    "            accuracies+=(prediction[i]==y[i])\n",
    "            \n",
    "        return accuracies / y.shape[0]\n",
    "    \n",
    "    \n",
    "    def test_SGD(self, x, y_onehot, y):\n",
    "        pred=np.zeros(y.shape[0])\n",
    "        avg_loss=0\n",
    "        for i in range (x.shape[0]):\n",
    "            _, _, _, _, _, os = self.forward(x[i])\n",
    "            loss=self.loss (y_onehot[i], os)\n",
    "            avg_loss+=loss\n",
    "            pred[i]=os.argmax()\n",
    "            \n",
    "        accuracy=self.accuracy_SGD(pred, y)    \n",
    "        return avg_loss / x.shape[0] , accuracy\n",
    "    \n",
    "   \n",
    "    def forward_mbatch(self, x):\n",
    "        #print ('forward minibtach')\n",
    "        a1 = np.dot ( x, self.W1.T) + self.b1 \n",
    "        #print('a1 = np.dot (x, self.W1.T) + self.b1')\n",
    "        #print('a1.shape =', a1.shape)\n",
    "        #print('a1 = ', a1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h1 = self.activation (a1)\n",
    "        #print('h1 = self.activation (a1)')\n",
    "        #print('h1.shape =', h1.shape)\n",
    "        #print('h1 = ', h1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        a2 = np.dot (h1, self.W2.T) + self.b2\n",
    "        #print('a2 = np.dot (h1, self.W2.T) + self.b2')\n",
    "        #print('a2.shape =', a2.shape)\n",
    "        #print('a2 = ', a2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h2 = self.activation (a2)\n",
    "        #print('h2 = self.activation (a2)')\n",
    "        #print('h2.shape =', h2.shape)\n",
    "        #print('h2 = ', h2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        oa = np.dot (h2, self.W3.T) + self.b3\n",
    "        #print('oa = np.dot (h2, self.W3.T) + self.b3')\n",
    "        #print('oa.shape =', oa.shape)\n",
    "        #print('oa = ', oa)\n",
    "        #print('\\n')\n",
    "        \n",
    "        os = self.softmax (oa, axis=1)\n",
    "        #print('os = softmax (oa)')\n",
    "        #print('os.shape =', os.shape)\n",
    "        #print('os = ', os)\n",
    "        #print('\\n')\n",
    "               \n",
    "        return a1, h1, a2, h2, oa, os\n",
    "    \n",
    "    #line 303\n",
    "        \n",
    "    def backward_mbatch(self, x, y, a1, h1, a2, h2, oa, os, batch_n, weight_decay=0):\n",
    "        #print ('backward minibatch')\n",
    "        \n",
    "        #print('x.shape = ', x.shape)\n",
    "        #print('y.shape = ', y.shape)\n",
    "        #print('os.shape = ', os.shape)\n",
    "        \n",
    "        \n",
    "        batch_n = x.shape[0]\n",
    "        bgrad_oa = os - y\n",
    "        #print('bgrad_oa.shape =', bgrad_oa.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_W3 = np.dot (bgrad_oa.T, h2) / batch_n  + weight_decay * self.W3\n",
    "        #print('bgrad_W3.shape =', bgrad_W3.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_b3 = bgrad_oa.mean(axis=0)\n",
    "        #print('bgrad_b3.shape =', bgrad_b3.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_h2 = np.dot (bgrad_oa, self.W3)\n",
    "        #print(' bgrad_h2.shape =', bgrad_h2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_a2 = (a2 > 0) * bgrad_h2\n",
    "        #print('bgrad_a2.shape =', bgrad_a2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_W2 = np.dot (bgrad_a2.T, h1) / batch_n  + weight_decay * self.W2\n",
    "        #print('bgrad_W2.shape =', bgrad_W2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_b2 = bgrad_a2.mean(axis=0) \n",
    "        #print('bgrad_b2.shape =', bgrad_b2.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_h1 = np.dot (bgrad_a2, self.W2)\n",
    "        #print('bgrad_h1.shape =', bgrad_h1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "     \n",
    "        bgrad_a1 = (a1 > 0) * bgrad_h1\n",
    "        #print('bgrad_a1.shape =', bgrad_a1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_W1 = np.dot (bgrad_a1.T, x) / batch_n  + weight_decay * self.W1\n",
    "        #print('bgrad_W1.shape =', bgrad_W1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrad_b1 = bgrad_a1.mean(axis=0)\n",
    "        #print('bgrad_b1.shape =', bgrad_b1.shape)\n",
    "        #print('\\n')\n",
    "        \n",
    "        bgrads=[bgrad_W3, bgrad_b3, bgrad_W2, bgrad_b2, bgrad_W1, bgrad_b1]\n",
    "   \n",
    "        return bgrads\n",
    "\n",
    "    #line 360\n",
    "\n",
    "    #Method taken fron homwork 3 in cours IFT6093\n",
    "    def loss_mbatch(self, os, y):\n",
    "        return (y * (-np.log(os))).sum(axis=1).mean(axis=0)     \n",
    "        \n",
    "    \n",
    "    #training with minibatch gradient decent\n",
    "    def train_mbatch(self, x, y_onehot, mb_size=100, learning_rate=1e-1, weight_decay=0):\n",
    "        average_loss=0\n",
    "        for i in range (0, x.shape[0], mb_size):\n",
    "            #print (i)\n",
    "            xi = x[i:(i+mb_size)]\n",
    "            yi = y_onehot[i:(i+mb_size)]\n",
    "        \n",
    "            losses = 0\n",
    "            a1, h1, a2, h2, oa, os = self.forward_mbatch(xi)\n",
    "            grads = self.backward_mbatch (xi, yi,a1, h1, a2, h2,oa, os, mb_size)\n",
    "            self.update(grads, learning_rate)\n",
    "            average_loss = self.loss_mbatch(os, yi) \n",
    "                          \n",
    "        return average_loss\n",
    "    \n",
    "    \n",
    "    #line 385\n",
    "    \n",
    "    def prediction_mbatch (self, x):\n",
    "        _, _, _, _, _, os = self.forward_mbatch(x)\n",
    "        return os.argmax(axis=1)\n",
    "    \n",
    "\n",
    "    def accuracy_mbatch (self, prediction, y):\n",
    "        accuracy = np.zeros(y.shape[0])\n",
    "        accuracy = prediction == y\n",
    "        return accuracy.mean(axis=0)\n",
    "    \n",
    "\n",
    "    def test_mbatch(self, x, y_onehot, y):\n",
    "        _, _, _, _, _, os = self.forward_mbatch(x)\n",
    "        loss = self.loss_mbatch (os, y_onehot)\n",
    "        accuracy=self.accuracy_mbatch (os.argmax(axis=1), y)\n",
    "        return loss, accuracy\n",
    "    \n",
    "    \n",
    "    def finite_difference():\n",
    "        \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax (self, x):\n",
    "        shiftx = x - np.max(x)\n",
    "        exps=np.exp(shiftx)\n",
    "        y=exps/np.sum(exps)\n",
    "        return y\n",
    "\n",
    "def relu (x):\n",
    "    y=np.maximum(0, x)\n",
    "    return y\n",
    "\n",
    "#function taken from IFT6093 cours\n",
    "def onehot(y, n_classes):\n",
    "    o = np.zeros(shape=(y.shape[0], n_classes))\n",
    "    for i in range(y.shape[0]):\n",
    "        o[i, int(y[i])] = 1\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (780,)\n",
      "\n",
      "\n",
      "y.shape =  (10,)\n",
      "\n",
      "\n",
      "a1 shape =  (500,)\n",
      "h1 shape =  (500,)\n",
      "a2 shape =  (300,)\n",
      "h2 shape =  (300,)\n",
      "oa shape =  (10,)\n",
      "os shape =  (10,)\n",
      "grad_W3 shape =  (10, 300)\n",
      "grad_b3 shape =  (10,)\n",
      "grad_W2 shape =  (300, 500)\n",
      "grad_b2 shape =  (300,)\n",
      "grad_W1 shape =  (500, 780)\n",
      "grad_b1 shape =  (500,)\n"
     ]
    }
   ],
   "source": [
    "#backpropagation for 1 exemple\n",
    "\n",
    "\n",
    "# self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2, initialization=zeros, mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_model= NN(780, 10, hidden_dims=(500,300))\n",
    "\n",
    "x = np.random.uniform(-1, 1, size=(780))\n",
    "print('x.shape = ', x.shape)\n",
    "print('\\n')\n",
    "\n",
    "y = np.zeros(shape=(10, ))\n",
    "y[1] = 1\n",
    "print('y.shape = ', y.shape)\n",
    "print('\\n')\n",
    "\n",
    "a1, h1, a2, h2, oa, os = NN_model.forward(x)\n",
    "\n",
    "#self,cache, x, y,a1, h1, a2, h2, oa, os, weight_decay=0)\n",
    "grads=NN_model.backward(x, y, a1, h1, a2, h2, oa, os)\n",
    "\n",
    "print ('a1 shape = ', a1.shape)\n",
    "print ('h1 shape = ', h1.shape)\n",
    "print ('a2 shape = ', a2.shape)\n",
    "print ('h2 shape = ', h2.shape)\n",
    "print ('oa shape = ', oa.shape)\n",
    "print ('os shape = ', os.shape)\n",
    "\n",
    "\n",
    "print ('grad_W3 shape = ', grads[0].shape)\n",
    "print ('grad_b3 shape = ', grads[1].shape)\n",
    "print ('grad_W2 shape = ', grads[2].shape)\n",
    "print ('grad_b2 shape = ', grads[3].shape)\n",
    "print ('grad_W1 shape = ', grads[4].shape)\n",
    "print ('grad_b1 shape = ', grads[5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  loss  2.3025850929940455\n",
      "epoch  1  loss  2.2130472649209176\n",
      "epoch  2  loss  2.125400286246365\n",
      "epoch  3  loss  2.039751468982383\n",
      "epoch  4  loss  1.956204563387701\n",
      "epoch  5  loss  1.8748581566171187\n",
      "epoch  6  loss  1.7958040494881427\n",
      "epoch  7  loss  1.7191256666613888\n",
      "epoch  8  loss  1.644896559738838\n",
      "epoch  9  loss  1.5731790633976404\n"
     ]
    }
   ],
   "source": [
    "#training 10 epoch for 1 exemple\n",
    "\n",
    "#x, y_onehot, n, learning_rate=1e-1, weight_decay=0\n",
    "epochs=10\n",
    "for epoch in range (epochs):\n",
    "    loss=NN_model.train_SGD(x, y, 1)\n",
    "    print('epoch ', epoch, ' loss ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (10, 780)\n",
      "y.shape =  (10, 10)\n",
      "\n",
      "\n",
      "epoch   loss   y_max   predic   acc   test_loss   test acc\n",
      "0   3.20601439446449   [1 2 7 6 9 4 1 6 5 5]   [1. 5. 5. 5. 9. 4. 5. 5. 5. 5.]   0.5   1.6660869534225675   0.5\n",
      "1   1.6632740399083197   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.001933608403367103   1.0\n",
      "2   0.0019319442185774956   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.0003890527627802244   1.0\n",
      "3   0.0003902510880783951   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.0003365426864646923   1.0\n",
      "4   0.000337420892743506   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.0002982424819241465   1.0\n",
      "5   0.00029892234861064775   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.00026871257461559236   1.0\n",
      "6   0.0002692588615660871   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.00024511434969236675   1.0\n",
      "7   0.00024556409246706307   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.00022568070132225645   1.0\n",
      "8   0.00022605988858385664   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.00020939225204362884   1.0\n",
      "9   0.00020971480264284038   [1 2 7 6 9 4 1 6 5 5]   [1. 2. 7. 6. 9. 4. 1. 6. 5. 5.]   1.0   0.00019554848521135276   1.0\n"
     ]
    }
   ],
   "source": [
    "#training for a small data set\n",
    "\n",
    "x = np.random.uniform(-1, 1, size=(10, 780))\n",
    "print('x.shape = ', x.shape)\n",
    "#print('x = ', x)\n",
    "#print('\\n')\n",
    "\n",
    "y = np.zeros(shape=(10, 10))\n",
    "y[0, 1] = 1\n",
    "y[1, 2] = 1\n",
    "y[2, 7] = 1\n",
    "y[3, 6] = 1\n",
    "y[4, 9] = 1\n",
    "y[5, 4] = 1\n",
    "y[6, 1] = 1\n",
    "y[7, 6] = 1\n",
    "y[8, 5] = 1\n",
    "y[9, 5] = 1\n",
    "\n",
    "print('y.shape = ', y.shape)\n",
    "#print('y = ', y)\n",
    "print('\\n')\n",
    "\n",
    "y_max= y.argmax(axis=1)\n",
    "\n",
    "# self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2, initialization=zeros, mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_model_2= NN(780, 10, hidden_dims=(500,300), initialization='glorot')\n",
    "\n",
    "print('epoch   loss   y_max   predic   acc   test_loss   test acc')\n",
    "\n",
    "epochs=10\n",
    "for epoch in range (epochs):\n",
    "   \n",
    "    \n",
    "    loss = NN_model_2.train_SGD(x, y, 10)\n",
    "    predic = NN_model_2.prediction_SGD (x)\n",
    "    acc = NN_model_2.accuracy_SGD (predic, y_max)\n",
    "    test_loss, test_acc = NN_model_2.test_SGD(x, y, y_max)\n",
    "    print(epoch, ' ',  loss, ' ', y_max, ' ', predic, ' ',  acc, ' ',  test_loss, ' ',  test_acc  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 3)\n",
      "880\n",
      "(880, 2)\n",
      "(880,)\n",
      "(880, 2)\n",
      "(220, 2)\n",
      "(220,)\n",
      "(220, 2)\n"
     ]
    }
   ],
   "source": [
    "#Code inspired from cours IFT6093 homework 3\n",
    "\n",
    "data_circles = np.loadtxt(open('cercles.txt','r'))\n",
    "cercle_x=np.array(data_circles[:, :-1])\n",
    "cercle_y=np.array(data_circles[:, -1])\n",
    "\n",
    "print (data_circles.shape)\n",
    "i=int(cercle_x.shape[0]*0.8)\n",
    "print (i)\n",
    "\n",
    "cercle_x_train=np.array(cercle_x[:i])\n",
    "cercle_y_train=np.array(cercle_y[:i])\n",
    "cercle_y_train_onehot= onehot (cercle_y_train, 2)\n",
    "\n",
    "cercle_x_test=np.array(cercle_x[i:])\n",
    "cercle_y_test=np.array(cercle_y[i:])\n",
    "cercle_y_test_onehot= onehot (cercle_y_test, 2)\n",
    "\n",
    "print (cercle_x_train.shape)\n",
    "print (cercle_y_train.shape)\n",
    "print (cercle_y_train_onehot.shape)\n",
    "print (cercle_x_test.shape)\n",
    "print (cercle_y_test.shape)\n",
    "print (cercle_y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       train loss         train accuracy      test loss      test accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:134: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:134: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "1     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "2     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "3     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "4     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "5     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "6     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "7     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "8     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "9     nan     0.5170454545454546     nan     0.5136363636363637\n",
      "Time with loop implementation: 45.725615 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  SGD training for cercle\n",
    "import time\n",
    "\n",
    "# self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2, initialization=zeros, mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "#initialization='glorot'\n",
    "\n",
    "NN_cercle= NN(2, 2, hidden_dims=(500,300), initialization='normal')\n",
    "\n",
    "#training 1 epoch for 1 exemple\n",
    "start_time = time.time()\n",
    "\n",
    "epoc=[]\n",
    "train_losses=[]\n",
    "train_accuracies=[]\n",
    "test_losses=[]\n",
    "test_accuracies=[]\n",
    "\n",
    "print('epoch       train loss         train accuracy      test loss      test accuracy')\n",
    "\n",
    "epochs=10\n",
    "for epoch in range (epochs):\n",
    "    \n",
    "    loss=NN_cercle.train_SGD(cercle_x_train, cercle_y_train_onehot, 1100)\n",
    "    \n",
    "    loss_train, accuracy_train = NN_cercle.test_SGD(cercle_x_train, cercle_y_train_onehot, cercle_y_train)\n",
    "    loss_test, accuracy_test = NN_cercle.test_SGD(cercle_x_test, cercle_y_test_onehot, cercle_y_test)\n",
    "    \n",
    "    epoc.append(epoch)\n",
    "    train_losses.append(loss_train)\n",
    "    train_accuracies.append(accuracy_train)\n",
    "    test_losses.append(loss_test)\n",
    "    test_accuracies.append(accuracy_test)\n",
    "    \n",
    "    \n",
    "    print(epoch, '   ', loss_train, '   ', accuracy_train, '   ', loss_test, '   ', accuracy_test)\n",
    "    \n",
    "time_SGD = time.time() - start_time\n",
    "\n",
    "print('Time with loop implementation: %f seconds\\n' % time_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (100, 780)\n",
      "\n",
      "\n",
      "y.shape =  (100, 10)\n",
      "\n",
      "\n",
      "epoch  0  loss  2.1508376640270965\n",
      "epoch  1  loss  1.9670613938018597\n",
      "epoch  2  loss  1.8047088244466487\n",
      "epoch  3  loss  1.66310672262223\n",
      "epoch  4  loss  1.5408850203566886\n",
      "epoch  5  loss  1.4362045046632366\n",
      "epoch  6  loss  1.3469966251278358\n",
      "epoch  7  loss  1.271165351499658\n",
      "epoch  8  loss  1.2067284032615495\n",
      "epoch  9  loss  1.1518981921774987\n"
     ]
    }
   ],
   "source": [
    "#Minibatch training for a small data set\n",
    "\n",
    "x = np.random.uniform(-1, 1, size=(100, 780))\n",
    "print('x.shape = ', x.shape)\n",
    "#print('x = ', x)\n",
    "print('\\n')\n",
    "\n",
    "y = np.zeros(shape=(100, 10))\n",
    "\n",
    "for i in range (y.shape[0]):\n",
    "    if ((random.choice((0, 1)))==0):\n",
    "        y[i, 0] = 1\n",
    "    else:\n",
    "        y[i, 1] = 1 \n",
    "\n",
    "\n",
    "print('y.shape = ', y.shape)\n",
    "#print('y = ', y)\n",
    "print('\\n')\n",
    "\n",
    "# input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_mbatch_1= NN(780, 10, hidden_dims=(500,300))\n",
    "\n",
    "loss_mbatch_1=0\n",
    "epochs=10\n",
    "for epoch in range (epochs): \n",
    "    #x, y_onehot, mb_size=100, learning_rate=1e-1, weight_decay=0\n",
    "    loss_mbatch_1=NN_mbatch_1.train_mbatch(x, y, mb_size=20)\n",
    "    print('epoch ', epoch, ' loss ', loss_mbatch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      train loss      train accuracy         test loss         test accuracy  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:365: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:365: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.7115546051370927    0.8625    2.033573287904418    0.8409090909090909\n",
      "1    0.0007204555005105597    1.0    0.0006079216220143687    1.0\n",
      "2    0.0003485370245609151    1.0    0.00030783045167299305    1.0\n",
      "3    0.000247421212343452    1.0    0.00022461669158998268    1.0\n",
      "4    0.00019784651458655347    1.0    0.00018316314528702644    1.0\n",
      "5    0.00016798692374034207    1.0    0.00015785179812454224    1.0\n",
      "6    0.00014785671782824728    1.0    0.00014044752563588007    1.0\n",
      "7    0.0001333095533555591    1.0    0.00012765002639403812    1.0\n",
      "8    0.00012229030325032242    1.0    0.00011783926483277914    1.0\n",
      "9    0.00011361124106843032    1.0    0.0001100188298338781    1.0\n",
      "10    0.0001065716318693709    1.0    0.00010361412982596549    1.0\n",
      "11    0.00010073017968835607    1.0    9.825725855854674e-05    1.0\n",
      "12    9.579424634873632e-05    1.0    9.369595828203043e-05    1.0\n",
      "13    9.155229545203071e-05    1.0    8.975614187602722e-05    1.0\n",
      "14    8.786334102948232e-05    1.0    8.630624195061189e-05    1.0\n",
      "15    8.46159709999679e-05    1.0    8.32542497929269e-05    1.0\n",
      "16    8.17316068476299e-05    1.0    8.052236528736513e-05    1.0\n",
      "17    7.914227295874985e-05    1.0    7.805167514531249e-05    1.0\n",
      "18    7.679752248871752e-05    1.0    7.580157219183943e-05    1.0\n",
      "19    7.464936184751457e-05    1.0    7.373917695118944e-05    1.0\n",
      "Time with minibatch gradient decent implementation: 7.019402 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  minibatch training for cercle\n",
    "\n",
    "import time\n",
    "\n",
    "# input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_cercle_mbatch= NN(2, 2, hidden_dims=(500,300), initialization='normal')\n",
    "\n",
    "#training 20 epoch for whole data set\n",
    "start_time = time.time()\n",
    "\n",
    "epoc=[]\n",
    "train_losses_mb=[]\n",
    "train_accuracies_mb=[]\n",
    "test_losses_mb=[]\n",
    "test_accuracies_mb=[]\n",
    "\n",
    "epochs=20\n",
    "\n",
    "print('epoch      train loss      train accuracy         test loss         test accuracy  ')\n",
    "\n",
    "for epoch in range (epochs): \n",
    "#x, y, mb_size=100, learning_rate=1e-1, weight_decay=0\n",
    "    loss=NN_cercle_mbatch.train_mbatch(cercle_x_train, cercle_y_train_onehot, mb_size=50)\n",
    "    \n",
    "    loss_train_mb, accuracy_train_mb = NN_cercle_mbatch.test_mbatch(cercle_x_train,\n",
    "                                                                    cercle_y_train_onehot,\n",
    "                                                                    cercle_y_train)\n",
    "    loss_test_mb, accuracy_test_mb = NN_cercle_mbatch.test_mbatch(cercle_x_test, \n",
    "                                                                  cercle_y_test_onehot, \n",
    "                                                                  cercle_y_test)\n",
    "    epoc.append(epoch)\n",
    "    train_losses_mb.append(loss_train_mb)\n",
    "    train_accuracies_mb.append(accuracy_train_mb)\n",
    "    test_losses_mb.append(loss_test_mb)\n",
    "    test_accuracies_mb.append(accuracy_test_mb)\n",
    "    \n",
    "    print(epoch, '  ', loss_train_mb, '  ', accuracy_train_mb , '  ', loss_test_mb,\n",
    "          '  ', accuracy_test_mb)\n",
    "    \n",
    "    \n",
    "time_mb = time.time() - start_time\n",
    "\n",
    "print('Time with minibatch gradient decent implementation: %f seconds\\n' % time_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (55000, 784)\n",
      "y_train shape =  (55000,)\n",
      "X_valid shape =  (5000, 784)\n",
      "y_valid shape =  (5000,)\n",
      "X_test shape =  (10000, 784)\n",
      "y_test shape =  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "from random import shuffle\n",
    "\n",
    "mndata = MNIST('C:/Users/Geo/Documents/Bioinformatica/maitrise/representationLearning/devoir 1')\n",
    "\n",
    "mndata.gz = True\n",
    "\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_test, y_test =  mndata.load_testing()\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "indices = list(range(len(X_train)))\n",
    "shuffle(indices)\n",
    "\n",
    "X_valid, y_valid = X_train[indices[55000:]], y_train[indices[55000:]]\n",
    "X_train, y_train = X_train[indices[:55000]], y_train[indices[:55000]]\n",
    "\n",
    "digit_y_train_onehot= onehot (y_train, 10)\n",
    "digit_y_valid_onehot= onehot (y_valid, 10)\n",
    "digit_y_test_onehot= onehot (y_test, 10)\n",
    "\n",
    "\n",
    "print('X_train shape = ', X_train.shape)\n",
    "print('y_train shape = ', y_train.shape)\n",
    "print('X_valid shape = ', X_valid.shape)\n",
    "print('y_valid shape = ', y_valid.shape)\n",
    "print('X_test shape = ', X_test.shape)\n",
    "print('y_test shape = ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. Weigths initialization\n",
    "\n",
    "# input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_digits_mbatch= NN(784, 10, hidden_dims=(500,300))\n",
    "\n",
    "#training 10 epochs\n",
    "start_time = time.time()\n",
    "\n",
    "epoc=[]\n",
    "train_losses_mb=[]\n",
    "train_accuracies_mb=[]\n",
    "valid_losses_mb=[]\n",
    "valid_accuracies_mb=[]\n",
    "test_losses_mb=[]\n",
    "test_accuracies_mb=[]\n",
    "\n",
    "epochs=10\n",
    "\n",
    "print('epoch      train loss      train accuracy         test loss         test accuracy  ')\n",
    "\n",
    "weigths=['zeros', 'normal', 'glorot']\n",
    "\n",
    "for i, init in enumerate(weigths, 0):\n",
    "    \n",
    "    print (init)\n",
    "    \n",
    "    # input_dim, output_dim, hidden_dims=(1024,2048), n_hidden=2, initialization='zeros', mode=',train',\n",
    "    # datapath=None,model_path=None\n",
    "\n",
    "    NN_digits= NN(784, 10, hidden_dims=(500,300), initialization=init)\n",
    "\n",
    "    for epoch in range (epochs): \n",
    "    #x, y, mb_size=100, learning_rate=1e-1, weight_decay=0\n",
    "        loss=NN_digits.train_mbatch(X_train, digit_y_train_onehot, mb_size=100)\n",
    "    \n",
    "        loss_train_mb, accuracy_train_mb = NN_digits.test_mbatch(X_train, digit_y_train_onehot, \n",
    "                                                                        y_train)\n",
    "    \n",
    "        loss_valid_mb, accuracy_valid_mb = NN_digits.test_mbatch(X_valid, digit_y_valid_onehot, \n",
    "                                                                        y_valid)\n",
    "    \n",
    "    \n",
    "        loss_test_mb, accuracy_test_mb = NN_digits.test_mbatch(X_test, digit_y_test_onehot,\n",
    "                                                                      y_test)\n",
    "        \n",
    "        print(epoch, '  ', loss_train_mb, '  ', accuracy_train_mb , '  ', loss_test_mb,\n",
    "          '  ', accuracy_test_mb)\n",
    "        \n",
    "        #epoc.append(epoch)\n",
    "        #train_losses_mb.append(loss_train_mb)\n",
    "        #train_accuracies_mb.append(accuracy_train_mb)\n",
    "        #valid_losses_mb.append(loss_valid_mb)\n",
    "        #valid_accuracies_mb.append(accuracy_valid_mb)\n",
    "        #test_losses_mb.append(loss_test_mb)\n",
    "        #test_accuracies_mb.append(accuracy_test_mb)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "time_mb = time.time() - start_time\n",
    "\n",
    "print('Time with minibatch gradient decent implementation: %f seconds\\n' % time_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gunzip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a642ee699e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgunzip\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m't10k-images-idx3-ubyte.gz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gunzip' is not defined"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "f=gunzip ['t10k-images-idx3-ubyte.gz']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7840016"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with gzip.open('t10k-images-idx3-ubyte.gz') as f:\n",
    "    file_content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images=np.array(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-405c62169ce6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-405c62169ce6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install python-mnist\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing,cross_validation,neighbors\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import os\n",
    "print(os.listdir(\"/u/jimenezg/Documents/IFT6023/Homework4\"))\n",
    "\n",
    "\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "df.head()\n",
    "#create matrix X and target vector y\n",
    "x = np.array(df.iloc[:,:-1])\n",
    "y = np.array(df.iloc[:,-1])\n",
    "#split into train and test\n",
    "split = 0.2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x, x_test, y, y_test = cross_validation.train_test_split(x, y, test_size=split,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-92aed4f207a2>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-92aed4f207a2>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def read_idx(t10k-images-idx3-ubyte.gz):\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def read_idx(t10k-images-idx3-ubyte.gz):\n",
    "    with open(t10k-images-idx3-ubyte.gz, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "return np.fromstring(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install python-mnist"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
