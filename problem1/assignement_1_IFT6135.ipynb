{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This class implementation is inspired from the NN implemented in cours IFT6093\n",
    "class NN(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "                 datapath=None,model_path=None):\n",
    "        \n",
    "        self.indim = input_dim\n",
    "        self.hd1 = hidden_dims[0] \n",
    "        self.hd2 = hidden_dims[1]\n",
    "        self.n_hidden = n_hidden\n",
    "        self.outd = output_dim\n",
    "        self.W1 = np.zeros(shape=(hidden_dims[0], input_dim))\n",
    "        print('W1.shape =', self.W1.shape)\n",
    "        #print('W1 = ', self.W1)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.b1 = np.zeros(hidden_dims[0])\n",
    "        print('b1.shape =', self.b1.shape)\n",
    "        #print('b1 = ', self.b1)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.W2 = np.zeros(shape=(hidden_dims[1], hidden_dims[0]))\n",
    "        print('W2.shape =', self.W2.shape)\n",
    "        #print('W2 = ', self.W2)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.b2 = np.zeros(hidden_dims[1])\n",
    "        print('b2.shape =', self.b2.shape)\n",
    "        #print('b2 = ', self.b2)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.W3 = np.zeros(shape=(output_dim, hidden_dims[1]))\n",
    "        print('W3.shape =', self.W3.shape)\n",
    "        #print('W3 = ', self.W3)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.b3 = np.zeros(output_dim)\n",
    "        print('b3.shape =', self.b3.shape)\n",
    "        #print('b3 = ', self.b3)\n",
    "        print('\\n')\n",
    "        \n",
    "        self.parameters = [self.W3, self.b3, self.W2, self.b2, self.W1, self.b1]\n",
    "        \n",
    "        \n",
    "    def initialize_weights_normal(self):\n",
    "        \n",
    "        self.W1 = np.random.normal(loc=0.0, scale=1.0, size=(self.hd1, self.indim))\n",
    "        self.W2 = np.random.normal(loc=0.0, scale=1.0, size=(self.hd2, self.hd1))\n",
    "        self.W3 = np.random.normal(loc=0.0, scale=1.0, size=(self.outd, self.hd2))\n",
    "    \n",
    "    \n",
    "    def initialize_weights_glorot(self,n_hidden,dims):\n",
    "        \n",
    "        dl1 = np.sqrt(6/(self.indim + self.hd1))\n",
    "        dl2 = np.sqrt(6/(self.hd1 + self.hd2))\n",
    "        dl3 = np.sqrt(6/(self.hd2 + self.outd))\n",
    "        self.W1 = np.random.uniform(low=(-dl1), high=dl1, size=(self.hd1, self.indim))\n",
    "        self.W2 = np.random.uniform(low=(-dl2), high=dl2, size=(self.hd2, self.hd1))\n",
    "        self.W3 = np.random.uniform(low=(-dl3), high=dl3, size=(self.outd, self.hd2))\n",
    "        \n",
    "        \n",
    "    #Method inspired from NN implemented in cours IFT6093\n",
    "    def activation (self,input):\n",
    "        return (input > 0) * input    \n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        a1 = np.dot (self.W1, x) + self.b1 \n",
    "        #print('a1 = np.dot (self.W1, x) + self.b1')\n",
    "        #print('a1.shape =', a1.shape)\n",
    "        #print('a1 = ', a1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h1 = self.activation (a1)\n",
    "        #print('h1 = self.activation (a1)')\n",
    "        #print('h1.shape =', h1.shape)\n",
    "        #print('h1 = ', h1)\n",
    "        #print('\\n')\n",
    "        \n",
    "        a2 = np.dot (self.W2, h1) + self.b2\n",
    "        #print('a2 = np.dot (self.W2, h1) + self.b2')\n",
    "        #print('a2.shape =', a2.shape)\n",
    "        #print('a2 = ', a2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        h2 = self.activation (a2)\n",
    "        #print('h2 = self.activation (a2)')\n",
    "        #print('h2.shape =', h2.shape)\n",
    "        #print('h2 = ', h2)\n",
    "        #print('\\n')\n",
    "        \n",
    "        oa = np.dot (self.W3, h2) + self.b3\n",
    "        #print('oa = np.dot (self.W3, h2) + self.b3')\n",
    "        #print('oa.shape =', oa.shape)\n",
    "        #print('oa = ', oa)\n",
    "        #print('\\n')\n",
    "        \n",
    "        os = softmax (oa)\n",
    "        #print('os = softmax (oa)')\n",
    "        #print('os.shape =', os.shape)\n",
    "        #print('os = ', os)\n",
    "        #print('\\n')\n",
    "               \n",
    "        return a1, h1, a2, h2, oa, os\n",
    "    \n",
    "    \n",
    "\n",
    "    #Method inspired from NN implemented in cours IFT6093\n",
    "    def loss (self,prediction,os):\n",
    "        return (y * (-np.log(os))).sum()\n",
    "    \n",
    "\n",
    "    def softmax (self,input,axis=1):\n",
    "        shiftx = x - np.max (x, axis=axis, keepdims=True)\n",
    "        exps = np.exp (shiftx)\n",
    "        y = exps / exps.sum (axis=axis, keepdims=True)\n",
    "        return y\n",
    "    \n",
    "\n",
    "    def backward(self, x, y, a1, h1, a2, h2, oa, os, weight_decay=0, cache=None):\n",
    "        #print('x.shape = ', x.shape)\n",
    "        #print('y.shape = ', y.shape)\n",
    "        #print('os.shape = ', os.shape)\n",
    "        grad_oa = os - y\n",
    "        #print('grad_oa.shape =', grad_oa.shape)\n",
    "        grad_W3 = np.outer (grad_oa, h2) + weight_decay * self.W3\n",
    "        #print('grad_W3.shape =', grad_W3.shape)\n",
    "        grad_b3 = grad_oa\n",
    "        #print('grad_b3.shape =', grad_b3.shape)\n",
    "        grad_h2 = np.dot (self.W3.T, grad_oa)\n",
    "        #print(' grad_h2.shape =', grad_h2.shape)\n",
    "        grad_a2 = (a2 > 0) * grad_h2\n",
    "        #print('grad_a2.shape =', grad_a2.shape)\n",
    "        grad_W2 = np.outer (grad_a2, h1) + weight_decay * self.W2\n",
    "        #print('grad_W2.shape =', grad_W2.shape)\n",
    "        grad_b2 = grad_a2 \n",
    "        #print('grad_b2.shape =', grad_b2.shape)\n",
    "        grad_h1 = np.dot (self.W2.T, grad_a2)\n",
    "        #print('grad_h1.shape =', grad_h1.shape)\n",
    "        grad_a1 = (a1 > 0) * grad_h1\n",
    "        #print('grad_a1.shape =', grad_a1.shape)\n",
    "        grad_W1 = np.outer (grad_a1, x) + weight_decay * self.W1\n",
    "        #print('grad_W1.shape =', grad_W1.shape)\n",
    "        grad_b1 = grad_a1\n",
    "        #print('grad_b1.shape =', grad_b1.shape)\n",
    "        \n",
    "        grads=[grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1]\n",
    "   \n",
    "        return grads\n",
    "\n",
    "\n",
    "\n",
    "    def update(self, grads, mu):\n",
    "        for p, grad in zip(self.parameters, grads):\n",
    "            p -= mu * grad\n",
    "        \n",
    "       \n",
    "\n",
    "    def train_SGD(self, x, y, epoch, n, learning_rate=1e-1, weight_decay=0):\n",
    "        print('x.shape = ', x.shape)\n",
    "        print('y.shape = ', y.shape)\n",
    "        avgLoss=np.zeros((epoch, 2))\n",
    "        i=0\n",
    "        while (i<epoch):\n",
    "            losses = 0\n",
    "            if (n==1):\n",
    "                a1, h1, a2, h2, oa, os = self.forward(x)\n",
    "                grads = self.backward(x, y, a1, h1, a2, h2, oa, os)\n",
    "                self.update(grads, learning_rate)\n",
    "                loss = self.loss(y, os)\n",
    "                losses += loss  \n",
    "                average_loss = losses / n\n",
    "            else:    \n",
    "                for j in range(x.shape[0]):\n",
    "                    #print ('xj.shape = ', x[j].shape)\n",
    "                    #print ('yj.shape = ', y[j].shape )\n",
    "                    a1, h1, a2, h2, oa, os = self.forward(x[j])\n",
    "                    grads = self.backward(x[j], y[j], a1, h1, a2, h2, oa, os)\n",
    "                    self.update(grads, learning_rate)\n",
    "                    loss = self.loss(y[j], os)\n",
    "                    losses += loss \n",
    "                    \n",
    "                average_loss = losses / n\n",
    "                #print (average_loss)\n",
    "            avgLoss[i, 0]= i\n",
    "            avgLoss[i, 1]= average_loss\n",
    "                \n",
    "            i+=1\n",
    "            \n",
    "        print ('avgLoss') \n",
    "        print ('\\n')\n",
    "        print (avgLoss)  \n",
    "        \n",
    "        return avgLoss\n",
    "    \n",
    "    \n",
    "    def forward_mbatch(self,input,labels):\n",
    "        pass\n",
    "        \n",
    "    def backward_mbatch(self,cache, x, y,a1, h1, a2, h2, oa, os, weight_decay=0):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    \n",
    "    #training with minibatch gradient decent\n",
    "    def train_mbatch(self, x, y, mb_size=100, learning_rate=1e-1, weight_decay=0):\n",
    "        \n",
    "        for i in range (0, x.shape[0], mb_size):\n",
    "        \n",
    "            xi = x[i:(i+mb_size)]\n",
    "            yi = y[i:(i+mb_size)]\n",
    "            \n",
    "            losses = 0\n",
    "            for j in range (mb_size):\n",
    "                a1, h1, a2, h2, oa, os = self.forward(self,xi,yi)\n",
    "                grad = self.backward(self, xi, yi,a1, h1, a2, h2,oa, os,cache=none)\n",
    "                self.parameters = update_parms(average_grads, mu)\n",
    "                loss = self.loss(self, yi, os)\n",
    "                losses += loss                          \n",
    "            average_loss = losses / xi.shape[0]\n",
    "                    \n",
    "            return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction (self, x):\n",
    "    predictions = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        a1, h1, a2, h2, oa, os = self.forward(x[i])\n",
    "        predictions[i] = os.argmax()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(self):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    shiftx = x - np.max(x)\n",
    "    exps=np.exp(shiftx)\n",
    "    y=exps/np.sum(exps)\n",
    "    return y\n",
    "\n",
    "def relu (x):\n",
    "    y=np.maximum(0, x)\n",
    "    return y\n",
    "\n",
    "#function taken from IFT6093 cours\n",
    "def onehot(y, n_classes):\n",
    "    o = np.zeros(shape=(y.shape[0], n_classes))\n",
    "    for i in range(y.shape[0]):\n",
    "        o[i, int(y[i])] = 1\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.shape = (500, 780)\n",
      "\n",
      "\n",
      "b1.shape = (500,)\n",
      "\n",
      "\n",
      "W2.shape = (300, 500)\n",
      "\n",
      "\n",
      "b2.shape = (300,)\n",
      "\n",
      "\n",
      "W3.shape = (10, 300)\n",
      "\n",
      "\n",
      "b3.shape = (10,)\n",
      "\n",
      "\n",
      "x.shape =  (780,)\n",
      "y.shape =  (10,)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (10, 300)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (10,)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (300, 500)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (300,)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (500, 780)\n",
      "gradients computed by bprop: \n",
      " grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1 (500,)\n"
     ]
    }
   ],
   "source": [
    "#backpropagation for 1 exemple\n",
    "\n",
    "\n",
    "# input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_model= NN(780, 10, hidden_dims=(500,300))\n",
    "\n",
    "x = np.random.uniform(-1, 1, size=(780))\n",
    "print('x.shape = ', x.shape)\n",
    "#print('x = ', x)\n",
    "#print('\\n')\n",
    "\n",
    "y = np.zeros(shape=(10, ))\n",
    "y[1] = 1\n",
    "print('y.shape = ', y.shape)\n",
    "#print('y = ', y)\n",
    "#print('\\n')\n",
    "\n",
    "a1, h1, a2, h2, oa, os = NN_model.forward(x)\n",
    "\n",
    "#self,cache, x, y,a1, h1, a2, h2, oa, os, weight_decay=0)\n",
    "grads=NN_model.backward(x, y, a1, h1, a2, h2, oa, os)\n",
    "\n",
    "for grad in grads:\n",
    "    print('gradients computed by bprop: \\n grad_W3, grad_b3, grad_W2, grad_b2, grad_W1, grad_b1',\n",
    "      grad.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (780,)\n",
      "y.shape =  (10,)\n",
      "avgLoss\n",
      "\n",
      "\n",
      "[[ 0.          2.30258509]\n",
      " [ 1.          2.21304726]\n",
      " [ 2.          2.12540029]\n",
      " [ 3.          2.03975147]\n",
      " [ 4.          1.95620456]\n",
      " [ 5.          1.87485816]\n",
      " [ 6.          1.79580405]\n",
      " [ 7.          1.71912567]\n",
      " [ 8.          1.64489656]\n",
      " [ 9.          1.57317906]]\n"
     ]
    }
   ],
   "source": [
    "#training 10 epoch for 1 exemple\n",
    "\n",
    "#x, y, epoch, n, learning_rate=1e-1, weight_decay=0\n",
    "loss=NN_model.train_SGD(x, y, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (10, 780)\n",
      "y.shape =  (10, 10)\n",
      "\n",
      "\n",
      "W1.shape = (500, 780)\n",
      "\n",
      "\n",
      "b1.shape = (500,)\n",
      "\n",
      "\n",
      "W2.shape = (300, 500)\n",
      "\n",
      "\n",
      "b2.shape = (300,)\n",
      "\n",
      "\n",
      "W3.shape = (10, 300)\n",
      "\n",
      "\n",
      "b3.shape = (10,)\n",
      "\n",
      "\n",
      "x.shape =  (10, 780)\n",
      "y.shape =  (10, 10)\n",
      "avgLoss\n",
      "\n",
      "\n",
      "[[  0.          22.83400771]\n",
      " [  1.          22.32312096]\n",
      " [  2.          21.90394395]\n",
      " [  3.          21.55921442]\n",
      " [  4.          21.27461712]\n",
      " [  5.          21.03843852]\n",
      " [  6.          20.84119783]\n",
      " [  7.          20.6752849 ]\n",
      " [  8.          20.5346269 ]\n",
      " [  9.          20.41439562]]\n",
      "[[  0.          22.83400771]\n",
      " [  1.          22.32312096]\n",
      " [  2.          21.90394395]\n",
      " [  3.          21.55921442]\n",
      " [  4.          21.27461712]\n",
      " [  5.          21.03843852]\n",
      " [  6.          20.84119783]\n",
      " [  7.          20.6752849 ]\n",
      " [  8.          20.5346269 ]\n",
      " [  9.          20.41439562]]\n"
     ]
    }
   ],
   "source": [
    "#training for a small data set\n",
    "\n",
    "x = np.random.uniform(-1, 1, size=(10, 780))\n",
    "print('x.shape = ', x.shape)\n",
    "#print('x = ', x)\n",
    "#print('\\n')\n",
    "\n",
    "y = np.zeros(shape=(10, 10))\n",
    "y[0, 1] = 1\n",
    "y[1, 2] = 1\n",
    "y[2, 7] = 1\n",
    "y[3, 6] = 1\n",
    "y[4, 9] = 1\n",
    "y[5, 4] = 1\n",
    "y[6, 1] = 1\n",
    "y[7, 6] = 1\n",
    "y[8, 5] = 1\n",
    "y[9, 5] = 1\n",
    "\n",
    "print('y.shape = ', y.shape)\n",
    "#print('y = ', y)\n",
    "print('\\n')\n",
    "\n",
    "# input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_model_2= NN(780, 10, hidden_dims=(500,300))\n",
    "\n",
    "#x, y, epoch, n, learning_rate=1e-1, weight_decay=0\n",
    "loss=NN_model_2.train_SGD(x, y, 10, 10)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cercles.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-2427178d3004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Code taken from cours IFT6093 homework 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_circles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cercles.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcercle_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_circles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_circles_target_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_circles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cercles.txt'"
     ]
    }
   ],
   "source": [
    "#Code taken from cours IFT6093 homework 3\n",
    "\n",
    "data_circles = np.loadtxt(open('cercles.txt','r'))\n",
    "cercle_x=np.array(data_circles[:, :-1])\n",
    "data_circles_target_onehot = onehot(data_circles[:, -1], 2)\n",
    "print (data_circles.shape)\n",
    "\n",
    "def plot_decision(model, axis=None):\n",
    "    if axis is None:\n",
    "        axis = plt.gca()\n",
    "    xx, yy = np.meshgrid(np.arange(-1.1, 1.11, 0.01),\n",
    "                         np.arange(-1.1, 1.11, 0.01))\n",
    "    Z = model.loop_predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    axis.contourf(xx, yy, Z, 1, alpha=0.8)\n",
    "    axis.scatter(data_circles[:, 0], data_circles[:, 1], c=data_circles[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.shape = (500, 2)\n",
      "\n",
      "\n",
      "b1.shape = (500,)\n",
      "\n",
      "\n",
      "W2.shape = (300, 500)\n",
      "\n",
      "\n",
      "b2.shape = (300,)\n",
      "\n",
      "\n",
      "W3.shape = (2, 300)\n",
      "\n",
      "\n",
      "b3.shape = (2,)\n",
      "\n",
      "\n",
      "x.shape =  (1100, 2)\n",
      "y.shape =  (1100, 2)\n",
      "a1 = np.dot (self.W1, x) + self.b1\n",
      "a1.shape = (500,)\n",
      "\n",
      "\n",
      "h1 = self.activation (a1)\n",
      "h1.shape = (500,)\n",
      "\n",
      "\n",
      "a2 = np.dot (self.W2, h1) + self.b2\n",
      "a2.shape = (300,)\n",
      "\n",
      "\n",
      "h2 = self.activation (a2)\n",
      "h2.shape = (300,)\n",
      "\n",
      "\n",
      "oa = np.dot (self.W3, h2) + self.b3\n",
      "oa.shape = (10,)\n",
      "\n",
      "\n",
      "os = softmax (oa)\n",
      "os.shape = (10,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NN' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-86b64fbecd10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;31m#x, y, epoch, n, learning_rate=1e-1, weight_decay=0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_SGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcercle_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_circles_target_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2999eeb478b8>\u001b[0m in \u001b[0;36mtrain_SGD\u001b[0;34m(self, x, y, epoch, n, learning_rate, weight_decay)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0myj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-2999eeb478b8>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, y, a1, h1, a2, h2, oa, os, weight_decay, cache)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x.shape = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y.shape = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'os.shape = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NN' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#  SGD training for cercle\n",
    "\n",
    "# self, input_dim, output_dim,hidden_dims=(1024,2048),n_hidden=2,mode=',train',\n",
    "# datapath=None,model_path=None\n",
    "\n",
    "NN_cercle= NN(2, 2, hidden_dims=(500,300))\n",
    "\n",
    "#training 1 epoch for 1 exemple\n",
    "\n",
    "#x, y, epoch, n, learning_rate=1e-1, weight_decay=0\n",
    "loss=NN_model.train_SGD(cercle_x, data_circles_target_onehot, 1, 1100)\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.zeros(shape=(10, 10 ))\n",
    "h[0, 1]=1\n",
    "h[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
